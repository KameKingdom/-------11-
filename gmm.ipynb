{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XNNNNF8LDw8F"
      },
      "source": [
        "# EM アルゴリズムによる GMM サンプル"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qbbkYeNv1X_S"
      },
      "source": [
        "**データサンプル**\n",
        "\n",
        "一番結果が出やすそうな [3ヶ国の気候データ](https://github.com/KameKingdom/-------11-/blob/main/3_countries_climate.csv)を使用する\n",
        "カラム１：平均気温，　カラム２：降水量\n",
        "\n",
        "結果悲惨な分布だったのでプログラムで作成したデータに変更\n",
        "\n",
        "またプログラムを書き換えて"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yWGwv1LL1772",
        "outputId": "83bb1f6e-d2cc-45aa-f049-5587a810b9ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Convergence speed:  2.2209593971811916\n",
            "Separation degree:  5.81859307638306\n",
            "Robustness to outliers:  2.625567347837022\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import csv\n",
        "import os\n",
        "from scipy.special import cbrt\n",
        "import scipy as sp\n",
        "import subprocess\n",
        "import matplotlib.pyplot as pl\n",
        "from pandas import DataFrame, Series\n",
        "\n",
        "directory = \"C:/Users/yudai/Desktop/KGU/3年生春学期/音楽情報処理/音楽情報処理第11回/\"  # データディレクトリ\n",
        "input_filename = \"cluster_data.csv\" #データ名\n",
        "\n",
        "def get_faithful_data():\n",
        "    f = open(os.path.join(directory, input_filename), \"r\")\n",
        "    reader = csv.reader(f)\n",
        "    header = next(reader)\n",
        "    ret = []\n",
        "    for row in reader:\n",
        "         x = float(row[0])\n",
        "         y = float(row[1])\n",
        "         ret.append([x, y])\n",
        "    return np.array(ret, dtype = np.float64)\n",
        "\n",
        "faithful = get_faithful_data()\n",
        "\n",
        "def draw_ring(mu, dev):\n",
        "    angles = np.linspace(0, 2 * np.pi, 100)\n",
        "    x = mu[0] + dev[0] * np.cos(angles)\n",
        "    y = mu[1] + dev[1] * np.sin(angles)\n",
        "    pl.plot(x, y, 'r-')\n",
        "\n",
        "def draw(mu, prec):\n",
        "    pl.clf()\n",
        "    pl.plot(faithful[:, 0], faithful[:, 1], 'b+')\n",
        "    pl.plot(mu[:, 0], mu[:, 1], 'go')\n",
        "    for i in range(len(mu)):\n",
        "        draw_ring(mu[i], np.sqrt(1. / prec[i]))\n",
        "    pl.xlim(0, 10)\n",
        "    pl.ylim(0, 10)\n",
        "    pl.pause(.1)\n",
        "\n",
        "def calc_estep(pi, mu, prec):\n",
        "    lpi = np.log(pi)\n",
        "    lprec = np.log(prec)\n",
        "    lz = lpi[None, :] + .5 * lprec.sum(1)[None, :] - .5 * (prec[None, :, :] *\n",
        "         (faithful[:, None, :] - mu[None, :, :]) ** 2).sum(2)\n",
        "    lz -= sp.special.logsumexp(lz, axis=1)[:, None]\n",
        "    return np.exp(lz)\n",
        "\n",
        "def calc_mstep(z):\n",
        "    pi = z.sum(0) / z.sum()\n",
        "    mu = (z[:, :, None] * faithful[:, None, :]).sum(0) / z.sum(0)[:, None]\n",
        "    prec = z.sum(0)[:, None] / (z[:, :, None] * ((faithful[:, None, :] -\n",
        "           mu[None, :, :]) ** 2)).sum(0)\n",
        "    return pi, mu, prec\n",
        "\n",
        "def evaluate_metrics(history, mu):\n",
        "    convergence_speed = np.mean(np.abs(np.diff(history)))\n",
        "    separation_degree = np.mean(np.linalg.norm(np.diff(mu, axis=0), axis=1))\n",
        "    robustness_to_outliers = np.mean(np.std([np.linalg.norm(faithful - mu_i, axis=1) for mu_i in mu], axis=1))\n",
        "\n",
        "    print(\"Convergence speed: \", convergence_speed)\n",
        "    print(\"Separation degree: \", separation_degree)\n",
        "    print(\"Robustness to outliers: \", robustness_to_outliers)\n",
        "\n",
        "def process_em(z, nstep):\n",
        "    history = []\n",
        "    def kl_loss(): \n",
        "        return np.abs(np.sum(pi) - 1) # 計算方法\n",
        "\n",
        "    for i in range(nstep):\n",
        "        pi, mu, prec = calc_mstep(z)\n",
        "        z = calc_estep(pi, mu, prec)\n",
        "        kl_loss_value = kl_loss() # Calculate KL divergence\n",
        "        history.append(kl_loss_value) # Append the KL divergence value to history\n",
        "        draw(mu, prec)\n",
        "    evaluate_metrics(history, mu)\n",
        "\n",
        "\n",
        "def process_sgd(z, nstep, use_adam=True):\n",
        "    history = [] # Initialize history\n",
        "    pi, mu, prec = calc_mstep(z)\n",
        "    lpi = tf.Variable(np.log(pi))\n",
        "    mu = tf.Variable(mu)\n",
        "    lprec = tf.Variable(np.log(prec))\n",
        "    faith = tf.constant(faithful)\n",
        "    if use_adam:\n",
        "        opt = tf.keras.optimizers.Adam(learning_rate=.1)\n",
        "    else:\n",
        "        opt = tf.keras.optimizers.RMSprop(learning_rate=.03)\n",
        "    for i in range(nstep):\n",
        "        def kl_loss():\n",
        "            penalty = tf.abs((tf.reduce_sum(tf.exp(lpi)) - 1))\n",
        "            lpi_normal = lpi - tf.reduce_logsumexp(lpi)\n",
        "            likelihood = (lpi_normal + .5 * tf.reduce_sum(lprec, axis=1))[None, :]\n",
        "            likelihood -= .5 * tf.reduce_sum(tf.exp(lprec)[None, :, :] *\n",
        "                          ((faith[:, None, :] - mu[None, :, :]) ** 2), axis=2)\n",
        "            return penalty - tf.reduce_sum(tf.reduce_logsumexp(likelihood, axis=1))\n",
        "        opt.minimize(kl_loss, var_list=[lpi, mu, lprec])\n",
        "        kl_loss_value = kl_loss() # Calculate KL divergence\n",
        "        history.append(kl_loss_value) # Append the KL divergence value to history\n",
        "        draw(mu.numpy(), tf.exp(lprec).numpy())\n",
        "    evaluate_metrics(history, mu.numpy())\n",
        "\n",
        "\n",
        "nsample = len(faithful)\n",
        "nclass = 3\n",
        "nstep = 400\n",
        "z = np.random.dirichlet(np.ones(nclass), nsample)\n",
        "use_em = False\n",
        "use_adam = True\n",
        "if use_em:\n",
        "    process_em(z, nstep)\n",
        "else:\n",
        "    process_sgd(z, nstep, use_adam)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
